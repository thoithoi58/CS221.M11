{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:22.516430Z",
     "start_time": "2022-01-10T08:32:20.362797Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:22.532429Z",
     "start_time": "2022-01-10T08:32:22.519435Z"
    }
   },
   "outputs": [],
   "source": [
    "def read(file):\n",
    "    with open(file, 'r', encoding='utf8') as f:\n",
    "        file = f.read().splitlines()\n",
    "    data = [[] for _ in range(len(file))]\n",
    "    for idx, i in enumerate(file):\n",
    "        a = i.split()\n",
    "        for j in a:\n",
    "            tmp = (j.rsplit('/',1))\n",
    "            data[idx].append((tmp[0], tmp[1]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:22.578463Z",
     "start_time": "2022-01-10T08:32:22.535440Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = read('corpus/train.txt')\n",
    "test_set = read('corpus/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:22.594457Z",
     "start_time": "2022-01-10T08:32:22.581436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2781\n",
      "1121\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:22.658454Z",
     "start_time": "2022-01-10T08:32:22.650432Z"
    }
   },
   "outputs": [],
   "source": [
    "test_tagged_words = 'I love you.'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:23.096454Z",
     "start_time": "2022-01-10T08:32:23.079437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'you.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:23.575472Z",
     "start_time": "2022-01-10T08:32:23.560464Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "{'SYM', 'VERB', 'ADP', 'ADJ', 'ADV', 'NOUN', 'SCONJ', 'AUX', 'CCONJ', 'PRON', 'NUM', 'X', 'PROPN', 'PUNCT', 'DET', 'PART'}\n"
     ]
    }
   ],
   "source": [
    "# let's check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:24.045437Z",
     "start_time": "2022-01-10T08:32:24.025432Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'you.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:25.124742Z",
     "start_time": "2022-01-10T08:32:25.118741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028\n"
     ]
    }
   ],
   "source": [
    "# let's check how many words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging algorithm using Hidden Markov Model (HMM)\n",
    "\n",
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. \n",
    "In other words, to every **word w**, assign **the tag t** that maximises the likelihood **P(t/w)**. \n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "* **P(w/t): is the emission probability** of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t). \n",
    "\n",
    "* **P(t): is the probability of tag (also transition probability)**, and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute emission probabilties for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:26.645793Z",
     "start_time": "2022-01-10T08:32:26.633795Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute emission probability for a given word for a given tag\n",
    "def word_given_tag(word, tag, train_bag=train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist) + 16\n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0] == word]\n",
    "    word_count_given_tag = len(w_in_tag) + 1\n",
    "\n",
    "    return (word_count_given_tag, tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute transition probabilties for a given tag and previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:27.501400Z",
     "start_time": "2022-01-10T08:32:27.485371Z"
    }
   },
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "#     print(len(tags))\n",
    "    \n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    \n",
    "    count_of_t1 = len(t1_tags) + 16\n",
    "    \n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    \n",
    "    count_t2_given_t1 = len(t2_given_t1) + 1\n",
    "    \n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:27.874398Z",
     "start_time": "2022-01-10T08:32:27.865390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NUM','NUM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:29.573207Z",
     "start_time": "2022-01-10T08:32:29.240185Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:30.089685Z",
     "start_time": "2022-01-10T08:32:30.075675Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-10T08:32:30.634662Z",
     "start_time": "2022-01-10T08:32:30.584684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NUM</th>\n",
       "      <th>X</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>DET</th>\n",
       "      <th>PART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.241791</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>0.092537</td>\n",
       "      <td>0.140299</td>\n",
       "      <td>0.047761</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.071642</td>\n",
       "      <td>0.170149</td>\n",
       "      <td>0.002985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.121711</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.049342</td>\n",
       "      <td>0.029605</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.088816</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.003289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.039801</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.606965</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.099502</td>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.005882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.097691</td>\n",
       "      <td>0.202487</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>0.166963</td>\n",
       "      <td>0.014210</td>\n",
       "      <td>0.063943</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.277087</td>\n",
       "      <td>0.017762</td>\n",
       "      <td>0.021314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.121622</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>0.031008</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.100775</td>\n",
       "      <td>0.054264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.056180</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.347594</td>\n",
       "      <td>0.053476</td>\n",
       "      <td>0.032086</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.085561</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.042781</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.074866</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.005348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.065089</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.124260</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.100592</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.053254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>0.091623</td>\n",
       "      <td>0.034031</td>\n",
       "      <td>0.081152</td>\n",
       "      <td>0.049738</td>\n",
       "      <td>0.049738</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.073298</td>\n",
       "      <td>0.151832</td>\n",
       "      <td>0.013089</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.107330</td>\n",
       "      <td>0.091623</td>\n",
       "      <td>0.115183</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.046980</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.218121</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.020134</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.077181</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.016779</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SYM      VERB       ADP       ADJ       ADV      NOUN     SCONJ  \\\n",
       "SYM    0.052632  0.052632  0.052632  0.052632  0.052632  0.105263  0.052632   \n",
       "VERB   0.002985  0.029851  0.241791  0.062687  0.092537  0.140299  0.047761   \n",
       "ADP    0.003289  0.121711  0.016447  0.078947  0.032895  0.118421  0.006579   \n",
       "ADJ    0.004975  0.014925  0.089552  0.039801  0.009950  0.606965  0.024876   \n",
       "ADV    0.005882  0.300000  0.058824  0.111765  0.070588  0.029412  0.047059   \n",
       "NOUN   0.001776  0.097691  0.202487  0.003552  0.031972  0.166963  0.014210   \n",
       "SCONJ  0.013514  0.054054  0.040541  0.067568  0.013514  0.121622  0.067568   \n",
       "AUX    0.007752  0.310078  0.031008  0.139535  0.100775  0.031008  0.007752   \n",
       "CCONJ  0.011236  0.101124  0.044944  0.089888  0.078652  0.179775  0.022472   \n",
       "PRON   0.005348  0.347594  0.053476  0.032086  0.090909  0.085561  0.010695   \n",
       "NUM    0.017857  0.017857  0.053571  0.071429  0.017857  0.142857  0.017857   \n",
       "X      0.050000  0.050000  0.050000  0.050000  0.050000  0.100000  0.050000   \n",
       "PROPN  0.023669  0.023669  0.065089  0.023669  0.005917  0.124260  0.005917   \n",
       "PUNCT  0.002618  0.094241  0.091623  0.034031  0.081152  0.049738  0.049738   \n",
       "DET    0.003356  0.046980  0.010067  0.218121  0.067114  0.489933  0.003356   \n",
       "PART   0.024390  0.097561  0.024390  0.048780  0.097561  0.390244  0.024390   \n",
       "\n",
       "            AUX     CCONJ      PRON       NUM         X     PROPN     PUNCT  \\\n",
       "SYM    0.052632  0.052632  0.052632  0.052632  0.052632  0.157895  0.052632   \n",
       "VERB   0.005970  0.005970  0.104478  0.005970  0.002985  0.011940  0.071642   \n",
       "ADP    0.016447  0.003289  0.049342  0.029605  0.006579  0.088816  0.016447   \n",
       "ADJ    0.014925  0.024876  0.004975  0.024876  0.004975  0.019900  0.099502   \n",
       "ADV    0.029412  0.017647  0.041176  0.005882  0.005882  0.011765  0.211765   \n",
       "NOUN   0.063943  0.046181  0.030195  0.005329  0.001776  0.017762  0.277087   \n",
       "SCONJ  0.040541  0.013514  0.243243  0.013514  0.013514  0.027027  0.054054   \n",
       "AUX    0.046512  0.015504  0.069767  0.023256  0.007752  0.015504  0.038760   \n",
       "CCONJ  0.056180  0.011236  0.067416  0.022472  0.011236  0.146067  0.056180   \n",
       "PRON   0.208556  0.005348  0.042781  0.005348  0.005348  0.005348  0.074866   \n",
       "NUM    0.017857  0.035714  0.017857  0.017857  0.017857  0.035714  0.482143   \n",
       "X      0.050000  0.050000  0.050000  0.050000  0.050000  0.050000  0.200000   \n",
       "PROPN  0.017751  0.076923  0.005917  0.100592  0.005917  0.183432  0.260355   \n",
       "PUNCT  0.028796  0.073298  0.151832  0.013089  0.010471  0.107330  0.091623   \n",
       "DET    0.020134  0.003356  0.026846  0.006711  0.003356  0.077181  0.003356   \n",
       "PART   0.048780  0.024390  0.024390  0.048780  0.024390  0.048780  0.024390   \n",
       "\n",
       "            DET      PART  \n",
       "SYM    0.052632  0.052632  \n",
       "VERB   0.170149  0.002985  \n",
       "ADP    0.407895  0.003289  \n",
       "ADJ    0.009950  0.004975  \n",
       "ADV    0.047059  0.005882  \n",
       "NOUN   0.017762  0.021314  \n",
       "SCONJ  0.202703  0.013514  \n",
       "AUX    0.100775  0.054264  \n",
       "CCONJ  0.089888  0.011236  \n",
       "PRON   0.021390  0.005348  \n",
       "NUM    0.017857  0.017857  \n",
       "X      0.050000  0.050000  \n",
       "PROPN  0.023669  0.053254  \n",
       "PUNCT  0.115183  0.002618  \n",
       "DET    0.016779  0.003356  \n",
       "PART   0.024390  0.024390  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viterbi Algorithm\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "1. Given a sequence of words\n",
    "2. iterate through the sequence\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained in step 3 above.\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-09T15:35:45.444380Z",
     "start_time": "2022-01-09T15:35:45.423372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['PUNCT', tag]\n",
    "#                 continue\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Vanilla Viterbi Algorithm on sampled test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-07T14:48:27.460182Z",
     "start_time": "2022-01-07T14:48:17.271162Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_set for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "\n",
    "vanilla_viterbi_accuracy = len(check)/len(tagged_seq)\n",
    "\n",
    "print(\"The accuracy of the Vanilla Viterbi Algorithm is -\", vanilla_viterbi_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
